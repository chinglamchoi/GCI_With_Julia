{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Julia’s Machine Learning Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Results sneak peek)\n",
    "Trial 1: Higher Dimensional Data:\n",
    "\n",
    "**Function**|**Flux runtime**|**Pytorch Runtime**|**Tensorflow Runtime**|**Flux Memory**|**Pytorch Memory**|**Tensorflow Memory**\n",
    ":-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:\n",
    "Conv|294.153 ms|17.902 ms|1.057 ms|73.83 MiB|400 B|2.20 KiB\n",
    "DepthwiseConv|59.748 ms|90.951 ms**|1.260 ms|73.83 MiB|688 B|2.20 KiB\n",
    "ConvTranspose|338.793 ms|59.849 ms|1.068 ms|114.28 MiB|416 B|2.20 KiB\n",
    "Dense|808.073 μs|527.187 μs|2.300 ms|24.25 KiB|400 B|192 B\n",
    "LSTM|18.129 ms|40.340 ms|146.397 ms|1.38 MiB|1.59 KiB|192 B\n",
    "RNN|4.770 ms|234.747 μs|64.971 ms|193.02 KiB|192 B|192 B\n",
    "BatchNorm|16.412 ms|5.932 ms|28.043 ms|25.00 MiB|192 B|192 B\n",
    "GroupNorm|16.322 ms|4.570 ms|19.457 ms|15.00 MiB|192 B|1.70 KiB\n",
    "LayerNorm|1.002 μs|6.099 ms|14.670 ms|1.50 KiB|192 B|720 B\n",
    "CrossCor|275.394 ms|18.884 ms|1.125 ms|73.84 MiB|400 B|1.52 KiB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial 0: Lower Dimensional Data:\n",
    "\n",
    "**Function**|**Flux runtime**|**Pytorch Runtime**|**Tensorflow Runtime**|**Flux Memory**|**Pytorch Memory**|**Tensorflow Memory**\n",
    ":-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:\n",
    "Conv|7.011 μs|31.213 μs|962.888 μs|3.80 KiB|400 B|2.20 KiB\n",
    "DepthwiseConv|11.024 μs|120.869 μs**|899.810 μs|11.30 KiB|688 B|2.20 KiB\n",
    "ConvTranspose|18.949 μs|25.888 μs|914.133 μs|19.83 KiB|416 B|2.20 KiB\n",
    "Dense|432.454 ns|12.770 μs|2.172 ms|592 B|400 B|192 B\n",
    "LSTM|19.842 ms|73.434 ms|217.620 ms|1.38 MiB|1.59 KiB|192 B\n",
    "RNN|4.324 ms|272.183 μs|72.779 ms|193.02 KiB|192 B|192 B\n",
    "BatchNorm|1.430 μs|132.111 μs|26.376 ms |2.28 KiB|192 B|192 B\n",
    "GroupNorm|4.974 μs|68.747 μs|19.314 ms|2.81 KiB|192 B|1.70 KiB\n",
    "LayerNorm|704.978 ns|20.479 μs|15.888 ms|880 B|192 B|720 B\n",
    "CrossCor|7.688 μs|39.505 μs|1.772 ms|4.00 KiB|400 B|1.52 KiB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dependecies & Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Pkg\n",
    "# Pkg.add(\"BenchmarkTools\")\n",
    "# Pkg.add(\"PyCall\")\n",
    "# Pkg.add(\"Flux\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "using BenchmarkTools\n",
    "using Flux\n",
    "using PyCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m Conda ─→ `C:\\Users\\CCL\\.julia\\packages\\Conda\\kLXeC\\deps\\build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m PyCall → `C:\\Users\\CCL\\.julia\\packages\\PyCall\\ttONZ\\deps\\build.log`\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CCL\\.julia\\conda\\3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n",
      "C:\\Users\\CCL\\.julia\\conda\\3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n",
      "C:\\Users\\CCL\\.julia\\conda\\3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n",
      "C:\\Users\\CCL\\.julia\\conda\\3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n",
      "C:\\Users\\CCL\\.julia\\conda\\3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n",
      "C:\\Users\\CCL\\.julia\\conda\\3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\n",
      "C:\\Users\\CCL\\.julia\\conda\\3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n",
      "C:\\Users\\CCL\\.julia\\conda\\3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n",
      "C:\\Users\\CCL\\.julia\\conda\\3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n",
      "C:\\Users\\CCL\\.julia\\conda\\3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n",
      "C:\\Users\\CCL\\.julia\\conda\\3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n",
      "C:\\Users\\CCL\\.julia\\conda\\3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PyObject <module 'tensorflow.python.keras.api._v1.keras.layers' from 'C:\\\\Users\\\\CCL\\\\.julia\\\\conda\\\\3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\keras\\\\api\\\\_v1\\\\keras\\\\layers\\\\__init__.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Readying Python environment\n",
    "\n",
    "ENV[\"PYTHON\"] = \"C:/Users/CCL/.julia/conda/3/python.exe\"\n",
    "Pkg.build(\"PyCall\")\n",
    "\n",
    "torch = pyimport(\"torch\")\n",
    "F = torch.nn.functional\n",
    "\n",
    "tf = pyimport(\"tensorflow\")\n",
    "rnn = tf.contrib.rnn\n",
    "layers = tf.keras.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Benchmarking Flux, Pytorch & Tensorflow\n",
    "\n",
    "I benchmark the time and memory needed to run the following functions: Conv, DepthwiseConv, ConvTranspose, Dense, LSTM, RNN, Normalization layers, and CrossCor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  73.83 MiB\n",
       "  allocs estimate:  46\n",
       "  --------------\n",
       "  minimum time:     261.279 ms (0.00% GC)\n",
       "  median time:      282.741 ms (2.42% GC)\n",
       "  mean time:        294.153 ms (6.10% GC)\n",
       "  maximum time:     396.088 ms (28.24% GC)\n",
       "  --------------\n",
       "  samples:          17\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Flux\n",
    "\n",
    "conv = Conv((2,2), 10=>30)\n",
    "conv_ = rand(128,128,10,10)\n",
    "@benchmark conv(conv_)\n",
    "#Get time only in sec: println(minimum(c.times)/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  400 bytes\n",
       "  allocs estimate:  10\n",
       "  --------------\n",
       "  minimum time:     14.778 ms (0.00% GC)\n",
       "  median time:      17.549 ms (0.00% GC)\n",
       "  mean time:        17.902 ms (0.00% GC)\n",
       "  maximum time:     29.156 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          279\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pytorch\n",
    "\n",
    "conv_t = torch.randn(10,10,128,128)\n",
    "conv_t1 = torch.randn(30,10,2,2)\n",
    "\n",
    "@benchmark F.conv2d(conv_t, conv_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  2.20 KiB\n",
       "  allocs estimate:  46\n",
       "  --------------\n",
       "  minimum time:     939.399 μs (0.00% GC)\n",
       "  median time:      1.006 ms (0.00% GC)\n",
       "  mean time:        1.057 ms (0.00% GC)\n",
       "  maximum time:     65.803 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          4710\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tensorflow\n",
    "\n",
    "conv_tf = tf.random.uniform((10,128,128,10))\n",
    "conv_tf1 = tf.random.uniform((2,2,10,30))\n",
    "@benchmark tf.nn.conv2d(conv_tf, conv_tf1, strides=(1,1,1,1), padding=\"VALID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 DepthwiseConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  73.83 MiB\n",
       "  allocs estimate:  46\n",
       "  --------------\n",
       "  minimum time:     47.266 ms (0.00% GC)\n",
       "  median time:      56.215 ms (13.02% GC)\n",
       "  mean time:        59.748 ms (16.10% GC)\n",
       "  maximum time:     162.613 ms (69.70% GC)\n",
       "  --------------\n",
       "  samples:          84\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Flux\n",
    "\n",
    "depthconv = DepthwiseConv((2,2), 10=>30)\n",
    "depthconv_ = rand(128,128,10,10)\n",
    "@benchmark depthconv(depthconv_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  688 bytes\n",
       "  allocs estimate:  20\n",
       "  --------------\n",
       "  minimum time:     57.272 ms (0.00% GC)\n",
       "  median time:      69.433 ms (0.00% GC)\n",
       "  mean time:        90.951 ms (0.00% GC)\n",
       "  maximum time:     521.443 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          58\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pytorch\n",
    "\n",
    "# DepthwiseConv: \"when groups == in_channels and out_channels = K* in_channles where K is a +ve int\"\n",
    "\n",
    "py\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "class DepthwiseConv(torch.nn.Module):\n",
    "    def __init__(self, in_c, K, out_c):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv2d(in_c, in_c*K, kernel_size=3, padding=1, groups=in_c)\n",
    "        self.pointwise = nn.Conv2d(in_c*K, out_c, kernel_size=2)\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x) \n",
    "        out = self.pointwise(out)\n",
    "        return out\n",
    "\"\"\"\n",
    "depthconv_t = py\"DepthwiseConv(10, 2, 30)\"\n",
    "@benchmark depthconv_t(torch.rand(10, 10, 128, 128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  2.20 KiB\n",
       "  allocs estimate:  46\n",
       "  --------------\n",
       "  minimum time:     956.001 μs (0.00% GC)\n",
       "  median time:      1.036 ms (0.00% GC)\n",
       "  mean time:        1.260 ms (0.00% GC)\n",
       "  maximum time:     593.603 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          3949\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tensorflow\n",
    "\n",
    "depthconv_tf = tf.random.uniform((10,128,128,10))\n",
    "depthconv_tf1 = tf.random.uniform((2,2,10,30))\n",
    "\n",
    "@benchmark tf.nn.conv2d(depthconv_tf, depthconv_tf1, strides=(1,1,1,1), padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ConvTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  114.28 MiB\n",
       "  allocs estimate:  108\n",
       "  --------------\n",
       "  minimum time:     317.023 ms (3.42% GC)\n",
       "  median time:      331.560 ms (3.31% GC)\n",
       "  mean time:        338.793 ms (3.16% GC)\n",
       "  maximum time:     384.906 ms (2.79% GC)\n",
       "  --------------\n",
       "  samples:          15\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Flux\n",
    "\n",
    "convtranspose = ConvTranspose((2,2), 10=>30)\n",
    "convtranspose_ = rand(128, 128, 10, 10)\n",
    "@benchmark convtranspose(convtranspose_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  416 bytes\n",
       "  allocs estimate:  10\n",
       "  --------------\n",
       "  minimum time:     50.390 ms (0.00% GC)\n",
       "  median time:      58.173 ms (0.00% GC)\n",
       "  mean time:        59.849 ms (0.00% GC)\n",
       "  maximum time:     85.969 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          84\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pytorch\n",
    "\n",
    "convtranspose_t = torch.randn(10,10,128,128)\n",
    "convtranspose_t1 = torch.randn(10,30,2,2)\n",
    "\n",
    "@benchmark F.conv_transpose2d(convtranspose_t, convtranspose_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  2.20 KiB\n",
       "  allocs estimate:  46\n",
       "  --------------\n",
       "  minimum time:     941.600 μs (0.00% GC)\n",
       "  median time:      1.005 ms (0.00% GC)\n",
       "  mean time:        1.068 ms (0.00% GC)\n",
       "  maximum time:     104.443 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          4659\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tensorflow\n",
    "\n",
    "convtranspose_tf = tf.random.uniform((10,128,128,10))\n",
    "convtranspose_tf1 = tf.random.uniform((2,2,10,30))\n",
    "@benchmark tf.nn.conv2d(convtranspose_tf, convtranspose_tf1, strides=(1,1,1,1), padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  24.25 KiB\n",
       "  allocs estimate:  3\n",
       "  --------------\n",
       "  minimum time:     521.500 μs (0.00% GC)\n",
       "  median time:      730.200 μs (0.00% GC)\n",
       "  mean time:        808.073 μs (0.43% GC)\n",
       "  maximum time:     11.835 ms (91.00% GC)\n",
       "  --------------\n",
       "  samples:          6109\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Flux\n",
    "\n",
    "dense = Dense(4096, 1000)\n",
    "dense_ = rand(4096)\n",
    "@benchmark dense(dense_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  400 bytes\n",
       "  allocs estimate:  10\n",
       "  --------------\n",
       "  minimum time:     355.999 μs (0.00% GC)\n",
       "  median time:      481.501 μs (0.00% GC)\n",
       "  mean time:        527.187 μs (0.00% GC)\n",
       "  maximum time:     3.968 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          9389\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pytorch\n",
    "\n",
    "dense_t = torch.randn(1, 4096)\n",
    "dense_t1 = torch.randn(1000, 4096)\n",
    "\n",
    "@benchmark F.linear(dense_t, dense_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\CCL\\.julia\\conda\\3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  192 bytes\n",
       "  allocs estimate:  6\n",
       "  --------------\n",
       "  minimum time:     2.001 ms (0.00% GC)\n",
       "  median time:      2.181 ms (0.00% GC)\n",
       "  mean time:        2.300 ms (0.00% GC)\n",
       "  maximum time:     8.206 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          2164\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tensorflow: Keras\n",
    "\n",
    "dense_tf = layers.Dense(1000)\n",
    "dense_tf1 = tf.random.uniform((1, 4096))\n",
    "\n",
    "@benchmark dense_tf(dense_tf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  1.38 MiB\n",
       "  allocs estimate:  40\n",
       "  --------------\n",
       "  minimum time:     16.665 ms (0.00% GC)\n",
       "  median time:      17.566 ms (0.00% GC)\n",
       "  mean time:        18.129 ms (0.73% GC)\n",
       "  maximum time:     31.251 ms (24.65% GC)\n",
       "  --------------\n",
       "  samples:          276\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Flux\n",
    "\n",
    "lstm = LSTM(512, 128)\n",
    "lstm_ = rand(512, 64)\n",
    "@benchmark lstm(lstm_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  1.59 KiB\n",
       "  allocs estimate:  42\n",
       "  --------------\n",
       "  minimum time:     28.388 ms (0.00% GC)\n",
       "  median time:      36.463 ms (0.00% GC)\n",
       "  mean time:        40.340 ms (0.00% GC)\n",
       "  maximum time:     66.987 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          124\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pytorch\n",
    "\n",
    "lstm_t = torch.nn.LSTM(512, 128, 1)\n",
    "lstm_t1 = torch.rand(50, 64, 512) #seq length, batch, input size \n",
    "# h0 = torch.rand(1, 64, 128) not passed in for fairness in benchmarking\n",
    "# c0 = torch.rand(1, 64, 128)\n",
    "@benchmark lstm_t(lstm_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  192 bytes\n",
       "  allocs estimate:  6\n",
       "  --------------\n",
       "  minimum time:     133.507 ms (0.00% GC)\n",
       "  median time:      141.474 ms (0.00% GC)\n",
       "  mean time:        146.397 ms (0.00% GC)\n",
       "  maximum time:     175.156 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          35\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tensorflow: Keras\n",
    "\n",
    "lstm_tf = layers.LSTM(128)\n",
    "lstm_tf1 = tf.random.uniform((50, 64, 512))\n",
    "\n",
    "@benchmark lstm_tf(lstm_tf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  193.02 KiB\n",
       "  allocs estimate:  23\n",
       "  --------------\n",
       "  minimum time:     4.257 ms (0.00% GC)\n",
       "  median time:      4.694 ms (0.00% GC)\n",
       "  mean time:        4.770 ms (0.56% GC)\n",
       "  maximum time:     22.202 ms (75.12% GC)\n",
       "  --------------\n",
       "  samples:          1046\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Flux\n",
    "\n",
    "rnn = RNN(512, 128)\n",
    "rnn_ = rand(512, 64)\n",
    "@benchmark rnn(rnn_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  192 bytes\n",
       "  allocs estimate:  6\n",
       "  --------------\n",
       "  minimum time:     135.200 μs (0.00% GC)\n",
       "  median time:      217.500 μs (0.00% GC)\n",
       "  mean time:        234.747 μs (0.00% GC)\n",
       "  maximum time:     864.299 μs (0.00% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pytorch\n",
    "\n",
    "rnn_t = torch.nn.RNNCell(512, 128)\n",
    "rnn_t1 = torch.rand(64, 512)\n",
    "@benchmark rnn_t(rnn_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  192 bytes\n",
       "  allocs estimate:  6\n",
       "  --------------\n",
       "  minimum time:     57.682 ms (0.00% GC)\n",
       "  median time:      60.417 ms (0.00% GC)\n",
       "  mean time:        64.971 ms (0.00% GC)\n",
       "  maximum time:     291.815 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          77\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tensorflow: Keras\n",
    "\n",
    "rnn_tf = layers.SimpleRNN(128)\n",
    "rnn_tf1 = tf.random.uniform((64, 1, 512))\n",
    "@benchmark rnn_tf(rnn_tf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Normalisation Layers: BatchNorm, GroupNorm, LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  25.00 MiB\n",
       "  allocs estimate:  18\n",
       "  --------------\n",
       "  minimum time:     12.471 ms (0.00% GC)\n",
       "  median time:      13.440 ms (0.00% GC)\n",
       "  mean time:        16.412 ms (14.97% GC)\n",
       "  maximum time:     38.760 ms (46.59% GC)\n",
       "  --------------\n",
       "  samples:          305\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Flux: BatchNorm\n",
    "\n",
    "bnorm = BatchNorm(10)\n",
    "bnorm_ = rand(128,128,10,10)\n",
    "@benchmark bnorm(bnorm_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  192 bytes\n",
       "  allocs estimate:  6\n",
       "  --------------\n",
       "  minimum time:     4.254 ms (0.00% GC)\n",
       "  median time:      5.100 ms (0.00% GC)\n",
       "  mean time:        5.932 ms (0.00% GC)\n",
       "  maximum time:     13.514 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          842\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pytorch: BatchNorm\n",
    "\n",
    "bnorm_t = torch.nn.BatchNorm2d(10)\n",
    "bnorm_t1 = torch.rand(10,10,128,128)\n",
    "@benchmark bnorm_t(bnorm_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  192 bytes\n",
       "  allocs estimate:  6\n",
       "  --------------\n",
       "  minimum time:     24.724 ms (0.00% GC)\n",
       "  median time:      25.608 ms (0.00% GC)\n",
       "  mean time:        28.043 ms (0.00% GC)\n",
       "  maximum time:     342.109 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          179\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tensorflow: Keras: BatchNorm\n",
    "\n",
    "bnorm_tf = layers.BatchNormalization()\n",
    "bnorm_tf1 = tf.random.uniform((10,128,128,10))\n",
    "@benchmark bnorm_tf(bnorm_tf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  15.00 MiB\n",
       "  allocs estimate:  43\n",
       "  --------------\n",
       "  minimum time:     13.730 ms (0.00% GC)\n",
       "  median time:      14.583 ms (0.00% GC)\n",
       "  mean time:        16.322 ms (9.08% GC)\n",
       "  maximum time:     30.292 ms (41.70% GC)\n",
       "  --------------\n",
       "  samples:          307\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Flux: GroupNorm\n",
    "\n",
    "gnorm = GroupNorm(6, 3)\n",
    "gnorm_ = rand(128, 128, 6, 10)\n",
    "@benchmark gnorm(gnorm_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  192 bytes\n",
       "  allocs estimate:  6\n",
       "  --------------\n",
       "  minimum time:     2.821 ms (0.00% GC)\n",
       "  median time:      4.287 ms (0.00% GC)\n",
       "  mean time:        4.570 ms (0.00% GC)\n",
       "  maximum time:     26.590 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          1094\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pytorch: GroupNorm\n",
    "\n",
    "gnorm_t = torch.nn.GroupNorm(3,6)\n",
    "gnorm_t1 = torch.rand(10,6,128,128)\n",
    "@benchmark gnorm_t(gnorm_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  1.70 KiB\n",
       "  allocs estimate:  34\n",
       "  --------------\n",
       "  minimum time:     17.839 ms (0.00% GC)\n",
       "  median time:      18.885 ms (0.00% GC)\n",
       "  mean time:        19.457 ms (0.00% GC)\n",
       "  maximum time:     37.315 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          257\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tensorfow: GroupNorm\n",
    "\n",
    "gnorm_tf1 = tf.random.uniform((10,128,128,6))\n",
    "@benchmark tf.contrib.layers.group_norm(gnorm_tf1, groups=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  1.50 KiB\n",
       "  allocs estimate:  5\n",
       "  --------------\n",
       "  minimum time:     529.468 ns (0.00% GC)\n",
       "  median time:      627.105 ns (0.00% GC)\n",
       "  mean time:        1.002 μs (13.28% GC)\n",
       "  maximum time:     54.320 μs (97.26% GC)\n",
       "  --------------\n",
       "  samples:          10000\n",
       "  evals/sample:     190"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Flux: LayerNorm\n",
    "\n",
    "lnorm = LayerNorm(10)\n",
    "lnorm_ = rand(1,10)\n",
    "@benchmark lnorm(lnorm_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  192 bytes\n",
       "  allocs estimate:  6\n",
       "  --------------\n",
       "  minimum time:     5.367 ms (0.00% GC)\n",
       "  median time:      5.913 ms (0.00% GC)\n",
       "  mean time:        6.099 ms (0.00% GC)\n",
       "  maximum time:     14.502 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          819\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pytorch: LayerNorm\n",
    "\n",
    "lnorm_t1 = torch.rand(10,10,128,128)\n",
    "lnorm_t = torch.nn.LayerNorm(lnorm_t1.size()[1:end])\n",
    "@benchmark lnorm_t(lnorm_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  720 bytes\n",
       "  allocs estimate:  18\n",
       "  --------------\n",
       "  minimum time:     12.861 ms (0.00% GC)\n",
       "  median time:      13.924 ms (0.00% GC)\n",
       "  mean time:        14.670 ms (0.00% GC)\n",
       "  maximum time:     30.908 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          341\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tensorfow: LayerNorm\n",
    "\n",
    "lnorm_tf1 = tf.random.uniform((10,10,128,128))\n",
    "@benchmark tf.contrib.layers.layer_norm(lnorm_tf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 CrossCor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  73.84 MiB\n",
       "  allocs estimate:  52\n",
       "  --------------\n",
       "  minimum time:     257.073 ms (0.00% GC)\n",
       "  median time:      275.567 ms (1.40% GC)\n",
       "  mean time:        275.394 ms (2.40% GC)\n",
       "  maximum time:     310.232 ms (4.88% GC)\n",
       "  --------------\n",
       "  samples:          19\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Flux\n",
    "\n",
    "cc = CrossCor((2,2), 10=>30)\n",
    "cc_ = rand(128,128,10,10)\n",
    "@benchmark cc(cc_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  400 bytes\n",
       "  allocs estimate:  10\n",
       "  --------------\n",
       "  minimum time:     16.443 ms (0.00% GC)\n",
       "  median time:      18.500 ms (0.00% GC)\n",
       "  mean time:        18.884 ms (0.00% GC)\n",
       "  maximum time:     25.857 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          265\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pytorch: Conv2d is already cross correlation\n",
    "\n",
    "cc_t = torch.randn(10,10,128,128)\n",
    "cc_t1 = torch.randn(30,10,2,2)\n",
    "\n",
    "@benchmark F.conv2d(cc_t, cc_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  1.52 KiB\n",
       "  allocs estimate:  28\n",
       "  --------------\n",
       "  minimum time:     973.900 μs (0.00% GC)\n",
       "  median time:      1.049 ms (0.00% GC)\n",
       "  mean time:        1.125 ms (0.00% GC)\n",
       "  maximum time:     3.419 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          4416\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tensorflow\n",
    "\n",
    "cc_tf1 = tf.random.uniform((10, 128, 128, 10))\n",
    "cc_tf2 = tf.random.uniform((2,2,10, 30))\n",
    "@benchmark tf.nn.convolution(cc_tf1, cc_tf2, padding=\"VALID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial 1: Higher Dimensional Data:\n",
    "\n",
    "**Function**|**Flux runtime**|**Pytorch Runtime**|**Tensorflow Runtime**|**Flux Memory**|**Pytorch Memory**|**Tensorflow Memory**\n",
    ":-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:\n",
    "Conv|294.153 ms|17.902 ms|1.057 ms|73.83 MiB|400 B|2.20 KiB\n",
    "DepthwiseConv|59.748 ms|90.951 ms**|1.260 ms|73.83 MiB|688 B|2.20 KiB\n",
    "ConvTranspose|338.793 ms|59.849 ms|1.068 ms|114.28 MiB|416 B|2.20 KiB\n",
    "Dense|808.073 μs|527.187 μs|2.300 ms|24.25 KiB|400 B|192 B\n",
    "LSTM|18.129 ms|40.340 ms|146.397 ms|1.38 MiB|1.59 KiB|192 B\n",
    "RNN|4.770 ms|234.747 μs|64.971 ms|193.02 KiB|192 B|192 B\n",
    "BatchNorm|16.412 ms|5.932 ms|28.043 ms|25.00 MiB|192 B|192 B\n",
    "GroupNorm|16.322 ms|4.570 ms|19.457 ms|15.00 MiB|192 B|1.70 KiB\n",
    "LayerNorm|1.002 μs|6.099 ms|14.670 ms|1.50 KiB|192 B|720 B\n",
    "CrossCor|275.394 ms|18.884 ms|1.125 ms|73.84 MiB|400 B|1.52 KiB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial 0: Lower Dimensionality Data:\n",
    "\n",
    "**Function**|**Flux runtime**|**Pytorch Runtime**|**Tensorflow Runtime**|**Flux Memory**|**Pytorch Memory**|**Tensorflow Memory**\n",
    ":-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:\n",
    "Conv|7.011 μs|31.213 μs|962.888 μs|3.80 KiB|400 B|2.20 KiB\n",
    "DepthwiseConv|11.024 μs|120.869 μs**|899.810 μs|11.30 KiB|688 B|2.20 KiB\n",
    "ConvTranspose|18.949 μs|25.888 μs|914.133 μs|19.83 KiB|416 B|2.20 KiB\n",
    "Dense|432.454 ns|12.770 μs|2.172 ms|592 B|400 B|192 B\n",
    "LSTM|19.842 ms|73.434 ms|217.620 ms|1.38 MiB|1.59 KiB|192 B\n",
    "RNN|4.324 ms|272.183 μs|72.779 ms|193.02 KiB|192 B|192 B\n",
    "BatchNorm|1.430 μs|132.111 μs|26.376 ms |2.28 KiB|192 B|192 B\n",
    "GroupNorm|4.974 μs|68.747 μs|19.314 ms|2.81 KiB|192 B|1.70 KiB\n",
    "LayerNorm|704.978 ns|20.479 μs|15.888 ms|880 B|192 B|720 B\n",
    "CrossCor|7.688 μs|39.505 μs|1.772 ms|4.00 KiB|400 B|1.52 KiB\n",
    "\n",
    "**_This function was not implemented in Pytorch so I had to use a custom implementation, written by Trevor Standley [https://discuss.pytorch.org/t/using-optimised-depthwise-convolutions/11819/15]._\n",
    "\n",
    "\n",
    "After rigorous testing, it is seen that Flux outperforms both Pytorch and Tensorflow in runtime for low dimensional data, executing functions several magnitudes faster. However, this advantage is not maintained when working with high dimensionality data representative of real-world use cases, where Flux performs generally performs worse than Pytorch and Tensorflow. This might be indicative of a scaling problem for data of higher dimensions. In terms of space efficiency, Pytorch performs the best, while Flux and Tensorflow achieve similar performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.0",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
